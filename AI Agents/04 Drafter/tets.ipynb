{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97bfae4",
   "metadata": {},
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage,HumanMessage,AIMessage,SystemMessage,ToolMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "#Global var to store doc content\n",
    "document_content = \"\"\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage],add_messages]\n",
    "\n",
    "\n",
    "@tool\n",
    "def update(content:str) -> str:\n",
    "    \"\"\"Update the document with provided content\"\"\"\n",
    "    global document_content # Standard procedure to interact with global variables in python\n",
    "    document_content = content\n",
    "    return f\"Document has been updated sucessfully! The current content is: \\n{document_content}\"\n",
    "\n",
    "@tool\n",
    "def save(filename:str) -> str:\n",
    "    \"\"\"Save the current document to a text file and finish the process.\n",
    "    Args:\n",
    "        filenames: Name for the text file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Just in case the LLM doesn't sift through the .txt automatically\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        filename=f\"{filename}.txt\"\n",
    "    \n",
    "    # Access the current draft\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(document_content)\n",
    "        print(f\"\\nðŸ’¾ Document has been saved to: {filename}\")\n",
    "        return f\"Document has been saved successfully to '{filename}'.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error saving document: {str(e)}\"\n",
    "    \n",
    "\n",
    "tools = [update, save]\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0.2,\n",
    ").bind_tools(tools) # Give the llm access to your tools\n",
    "\n",
    "def our_agent(state:AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    You are Drafter, a helpful writing assistant. You are going to help the user update and modify documents.\n",
    "    \n",
    "    - If the user wants to update or modify content, use the 'update' tool with the complete updated content.\n",
    "    - If the user wants to save and finish, you need to use the 'save' tool.\n",
    "    - Make sure to always show the current document state after modifications.\n",
    "    \n",
    "    The current document content is:{document_content}\n",
    "    \"\"\")\n",
    "    # Introduction messages\n",
    "    if not state[\"messages\"]:\n",
    "        user_input = \"I'm ready to help you update a document. What would you like to create?\"\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "    else:\n",
    "        user_input = input(\"\\nWhat would you like to do with the document? \")\n",
    "        print(f\"\\nðŸ‘¤ USER: {user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    all_messages = [system_prompt] + list(state[\"messages\"]) + [user_message]\n",
    "    response = llm.invoke(all_messages)\n",
    "\n",
    "    # PRINT STATEMENTS THAT MAKE TERMINAL LOOK NICE\n",
    "    print(f\"\\nðŸ¤– AI: {response.content}\")\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        print(f\"ðŸ”§ USING TOOLS: {[tc['name'] for tc in response.tool_calls]}\")\n",
    "\n",
    "    #RETURN\n",
    "    return {\"messages\": list(state[\"messages\"]) + [user_message, response]}\n",
    "\n",
    "\n",
    "def should_continue(state:AgentState)->str:\n",
    "    \"\"\"Function I made to print the messages in a more readable format\"\"\"\n",
    "    messages = state['messages']\n",
    "    if not messages:\n",
    "        return \"continue\"\n",
    "    \n",
    "    # This looks for the most recent tool message....\n",
    "    for message in reversed(messages):\n",
    "        # ... and checks if this is a ToolMessage resulting from 'save' function\n",
    "        if (isinstance(message, ToolMessage) and \n",
    "            \"saved\" in message.content.lower() and\n",
    "            \"document\" in message.content.lower()):\n",
    "            return \"end\" # goes to the end edge which leads to the endpoint\n",
    "        \n",
    "    return \"continue\"\n",
    "\n",
    "def print_messages(messages):\n",
    "    \"\"\"Function I made to print the messages in a more readable format\"\"\"\n",
    "    if not messages:\n",
    "        return\n",
    "    \n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"\\nðŸ› ï¸ TOOL RESULT: {message.content}\")\n",
    "\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"Agent\",our_agent)\n",
    "graph.add_node(\"Tools\",ToolNode(tools))\n",
    "\n",
    "graph.set_entry_point(\"Agent\")\n",
    "graph.add_edge(\"Agent\",\"Tools\")\n",
    "\n",
    "graph.add_conditional_edges(\"tools\",should_continue,\n",
    "                            {\n",
    "                                \"continue\":\"agent\",\n",
    "                                \"end\":END,\n",
    "                            },)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc83a34d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    120\u001b[39m graph.add_edge(\u001b[33m\"\u001b[39m\u001b[33mAgent\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mTools\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    122\u001b[39m graph.add_conditional_edges(\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m,should_continue,\n\u001b[32m    123\u001b[39m                             {\n\u001b[32m    124\u001b[39m                                 \u001b[33m\"\u001b[39m\u001b[33mcontinue\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    125\u001b[39m                                 \u001b[33m\"\u001b[39m\u001b[33mend\u001b[39m\u001b[33m\"\u001b[39m:END,\n\u001b[32m    126\u001b[39m                             },)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m app = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\There\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\graph\\state.py:861\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    858\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    870\u001b[39m output_channels = (\n\u001b[32m    871\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m     ]\n\u001b[32m    879\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\There\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\graph\\state.py:785\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    789\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'tools'"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage,HumanMessage,AIMessage,SystemMessage,ToolMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "#Global var to store doc content\n",
    "document_content = \"\"\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage],add_messages]\n",
    "\n",
    "\n",
    "@tool\n",
    "def update(content:str) -> str:\n",
    "    \"\"\"Update the document with provided content\"\"\"\n",
    "    global document_content # Standard procedure to interact with global variables in python\n",
    "    document_content = content\n",
    "    return f\"Document has been updated sucessfully! The current content is: \\n{document_content}\"\n",
    "\n",
    "@tool\n",
    "def save(filename:str) -> str:\n",
    "    \"\"\"Save the current document to a text file and finish the process.\n",
    "    Args:\n",
    "        filenames: Name for the text file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Just in case the LLM doesn't sift through the .txt automatically\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        filename=f\"{filename}.txt\"\n",
    "    \n",
    "    # Access the current draft\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(document_content)\n",
    "        print(f\"\\nðŸ’¾ Document has been saved to: {filename}\")\n",
    "        return f\"Document has been saved successfully to '{filename}'.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error saving document: {str(e)}\"\n",
    "    \n",
    "\n",
    "tools = [update, save]\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0.2,\n",
    ").bind_tools(tools) # Give the llm access to your tools\n",
    "\n",
    "def our_agent(state:AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    You are Drafter, a helpful writing assistant. You are going to help the user update and modify documents.\n",
    "    \n",
    "    - If the user wants to update or modify content, use the 'update' tool with the complete updated content.\n",
    "    - If the user wants to save and finish, you need to use the 'save' tool.\n",
    "    - Make sure to always show the current document state after modifications.\n",
    "    \n",
    "    The current document content is:{document_content}\n",
    "    \"\"\")\n",
    "    # Introduction messages\n",
    "    if not state[\"messages\"]:\n",
    "        user_input = \"I'm ready to help you update a document. What would you like to create?\"\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "    else:\n",
    "        user_input = input(\"\\nWhat would you like to do with the document? \")\n",
    "        print(f\"\\nðŸ‘¤ USER: {user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    all_messages = [system_prompt] + list(state[\"messages\"]) + [user_message]\n",
    "    response = llm.invoke(all_messages)\n",
    "\n",
    "    # PRINT STATEMENTS THAT MAKE TERMINAL LOOK NICE\n",
    "    print(f\"\\nðŸ¤– AI: {response.content}\")\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        print(f\"ðŸ”§ USING TOOLS: {[tc['name'] for tc in response.tool_calls]}\")\n",
    "\n",
    "    #RETURN\n",
    "    return {\"messages\": list(state[\"messages\"]) + [user_message, response]}\n",
    "\n",
    "\n",
    "def should_continue(state:AgentState)->str:\n",
    "    \"\"\"Function I made to print the messages in a more readable format\"\"\"\n",
    "    messages = state['messages']\n",
    "    if not messages:\n",
    "        return \"continue\"\n",
    "    \n",
    "    # This looks for the most recent tool message....\n",
    "    for message in reversed(messages):\n",
    "        # ... and checks if this is a ToolMessage resulting from 'save' function\n",
    "        if (isinstance(message, ToolMessage) and \n",
    "            \"saved\" in message.content.lower() and\n",
    "            \"document\" in message.content.lower()):\n",
    "            return \"end\" # goes to the end edge which leads to the endpoint\n",
    "        \n",
    "    return \"continue\"\n",
    "\n",
    "def print_messages(messages):\n",
    "    \"\"\"Function I made to print the messages in a more readable format\"\"\"\n",
    "    if not messages:\n",
    "        return\n",
    "    \n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"\\nðŸ› ï¸ TOOL RESULT: {message.content}\")\n",
    "\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"Agent\",our_agent)\n",
    "graph.add_node(\"Tools\",ToolNode(tools))\n",
    "\n",
    "graph.set_entry_point(\"Agent\")\n",
    "graph.add_edge(\"Agent\",\"Tools\")\n",
    "\n",
    "graph.add_conditional_edges(\"tools\",should_continue,\n",
    "                            {\n",
    "                                \"continue\":\"agent\",\n",
    "                                \"end\":END,\n",
    "                            },)\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b2527d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m app=\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image,display\n\u001b[32m      3\u001b[39m display(Image(app.get_graph().draw_mermaid_png()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\There\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\graph\\state.py:861\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    858\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    870\u001b[39m output_channels = (\n\u001b[32m    871\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m     ]\n\u001b[32m    879\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\There\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\graph\\state.py:785\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    789\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'tools'"
     ]
    }
   ],
   "source": [
    "app=graph.compile()\n",
    "from IPython.display import Image,display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
